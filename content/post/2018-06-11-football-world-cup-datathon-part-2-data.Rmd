---
title: 'Football World Cup Datathon - Part 2: Data Aquisition'
author: James Day
date: '2018-06-11'
slug: football-world-cup-datathon-part-2
categories:
  - Football
  - World Cup Datathon
tags: []
---

I introduced the Betfair World Cup Datathon in [Part 1](https://plussixoneblog.com/post/football-world-cup-datathon-part-1) of this series of posts. In this second post, I'm going to focus on getting data. Given I don't have a lot of domain knowledge, I can't go into developing anything too advanced myself. As such, getting as much data as possible is going to be my best bet. This post shows all the data sources I've been able to easily access. 

```{r setup}
# Set some defaults and load libraries
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(pacman)
pacman::p_load(tidyverse, here, ggthemes, rvest, lubridate)
```

## Load Data
### Betfair
Betfair has provided all participants with data. To get that data you need to sign up to the competition, which you can do [here](https://www.betfair.com.au/hub/insights/minihubs/world-cup-datathon/). I'm also hosting it on Github [here](https://github.com/jimmyday12/plussixoneblog/blob/master/projects/world-cup-2018/wc_datathon_dataset.csv).

```{r load_betfair, warning=FALSE, message=FALSE}
# Load betfair data
betfair_dat <- read_csv(here::here("projects", "world-cup-2018", "wc_datathon_dataset.csv"))

# View
glimpse(betfair_dat)
summary(betfair_dat)
```

So - it looks like each row is a game that contains the final score, the tournament, who is the home team and then the odds of each outcome. There is quite a lot of games (~14k) which is good! There are some missing values which is a bit annoying but we'll work out how to deal with that later! I'll be doing a more detailed data exploration in Part 3. 




### Kaggle Odds dataset
I found this data set on [Kaggle](https://www.kaggle.com/austro/beat-the-bookie-worldwide-football-dataset/data) that has the odds for almost 500k matches! Most of those are league games but we should be able to get rid of those when we join it to our other data sets.  

```{r load_kaggle, message=FALSE, warning=FALSE}
# Load odds data
odds_dat <- read_csv(here::here("projects", "world-cup-2018", "closing_odds.csv"))

# View
glimpse(odds_dat)
summary(odds_dat)
```

So this data set has different odds but has it for way more data and nothing missing. One problem I might have is that I'm not sure I can get these specific odds (bookies) easily for the upcoming World Cup games. If I want to include it in a model that will be an issue. I'll need to see what I can get. 

### FIFA
Logically, if we wanted to try and assess team ratings we could look towards the official [FIFA World rankings](https://www.fifa.com/fifa-world-ranking/ranking-table/men/index.html). These are used for primarily for seeding in tournaments, such as the World Cup. In researching for this project, I found that these are generally [critisied for being too simplistic](https://en.wikipedia.org/wiki/FIFA_World_Rankings) and most people prefer ELO rating systems. Nonetheless, it is a data set I am able to get access to and, given it is used for seeding in the World Cup, there may be some value for including them in a model. 

#### Scraping data
The code to get this information has been adapted from a [Github respository](https://github.com/rboberg/rross/blob/master/Soccer/2014/WorldCup/Scrape%20Fifa%20World%20Rankings.R) I found from Github user [Ross Boberg](https://github.com/rboberg). 

If you would prefer to take a scripted version of my code below, you can find that [here](https://github.com/jimmyday12/plussixoneblog/blob/master/projects/world-cup-2018/scrape_fifa.R). You can also just grab the data directly from [here](https://github.com/jimmyday12/plussixoneblog/blob/master/projects/world-cup-2018/fifa_rank_history.csv).

Firstly, we have to create a function that builds us a URL. We can then use this to get all the combinations of URLS we need. Based on Ross' work, we know that each URL contains a query for `rank`, `confediration`, `gender` and `page`. This function will dynamically generate the URL with the values for those queries. 

```{r load_fifa, echo=FALSE, message=FALSE, warning=FALSE}
# Create function to generate URL
get_ranking_table_URL <- function(rank, confederation, gender = "m", page = 1){
  base <- "http://www.fifa.com/worldranking/rankingtable"
  tail <- "_ranking_table.html"
  return(paste0(base,
                "/gender=", gender,
                "/rank=", rank,
                "/confederation=", confederation,
                "/page=", page,
                "/",
                tail)
  ) 
}
```

Now, let's generate a bunch of URLs. Based on Ross's code, I know the rough start and end points for `rank` and I also know the id's of the `confedirations`. 

```{r generate_urls, message=FALSE, warning=FALSE}
# Specify parameters
start_rank = 286 # the last update (as of Jun 5th, 2018)
end_rank = 57 # corresponds to Jan99, when point method was revised
conf_ids = c(23913, 23914, 23915, 23916, 25998, 27275)

rank <- rep(start_rank:end_rank, each = length(conf_ids))
conf_vec <- rep(conf_ids, times = length(start_rank:end_rank))

urls <- rank %>%
  map2_chr(conf_vec, ~ get_ranking_table_URL(rank = .x, confederation = .y))

length(urls)
```

Now we've got a list of URLs to search through - I can pass them to `read_html` and generate local HTML files for me to use. This is the most time consuming part of this process - this function took my laptop ~13 min to run so be mindful if you are following along! I've actually just done the first 10 of 1380 for this blog post so comment that out if needed.

```{r read_htmls, message=FALSE, warning=FALSE}
# Uncomment 1st line and comment out 2nd line to do all data. I've just done 1st 10 for illustration purposes
# ind <- seq_along(urls)
ind <- 1:10 

htmls <- urls[ind] %>%
  map(xml2::read_html)

```

Success! Now we've got those htmls, we can do some extraction and data cleaning. We basically just need to get the dates and then the table of data on each page. Again, using the handy `purrr` package to do our heavy lifting makes this relatively simple.

```{r clean_fifa, message=FALSE, warning=FALSE}
# Read date
dates <- htmls %>% 
  map(~html_nodes(.x, ".lb")) %>%
  map(html_text) %>%
  map_chr(~str_remove(.x, "Last Updated ")) %>%
  map(dmy) 

# Read Tables
tables <- htmls %>% 
  map(~html_nodes(.x, "#tbl_rankingTable")) %>%
  map(html_table) %>%
  map(as.data.frame)

# Add date, conf id and make into one dataframe
fifa_dat <- tables %>%
  map2(dates, ~ .x %>% mutate(Date = .y)) %>%
  map2(conf_vec[ind], ~ .x %>% mutate(Conference_id = .y)) %>%
  reduce(bind_rows) %>%
  select(Date, Team, Pts, Conference_id) %>%
  arrange(Date, desc(Pts))

head(fifa_dat)
```
For the purposes of joining my Data sets, I need the full set of data (the above code is just for the last 10 ratings). [Here's some I prepared earlier!](https://github.com/jimmyday12/plussixoneblog/blob/master/projects/world-cup-2018/fifa_rank_history.csv).

```{r load_fifa_full, message=FALSE, warning=FALSE}
fifa_dat <- read_csv(here::here("projects", "world-cup-2018", "fifa_rank_history.csv"))
glimpse(fifa_dat)
summary(fifa_dat)
```

### Other sources
I had looked at some other sources but found it either too tricky or they didn't have wide enough covered. These including trying to include 'team value' information from Transfermarkt. I think this would be awesome but I could only get the value of each of the current World Cup squads. I'm sure it's possible to try and find backdate information but I don't have the time.

Another option that would be cool would be to use the EA Sports FIFA player ratings as a bit of a proxy for the talent in each team. I did find some promising websites but they were ultimately going to take too much time to scrape. 

# Combining dataset
Now that we have acquired our data, we need to combine it in some way to make one big data file. Again, I want this to be one row per match and it's going to be fairly wide. 

Now, what we want is to add the FIFA data to our betfair odds. This isn't going to a simple join I don't think - we want to match the home team name and the date of the match to the closest date and team in our FIFA file and return the rating. I'm pretty sure that the FIFA ratings get updated once per month so we may be able to join on `year`, `month` and `team`

```{r combine, message=FALSE, warning=FALSE}
# Add in a date/month to fifa and betfair data
fifa_dat <- fifa_dat %>%
  mutate(year = year(Date),
         month = month(Date)) %>%
  select(year, month, Team, Pts) 

betfair_dat <- betfair_dat %>%
  mutate(year = year(date),
         month = month(date))

odds_dat <- odds_dat %>%
  select(match_id, match_date, home_team, away_team, avg_odds_home_win:avg_odds_away_win)

# Join data together
dat <- betfair_dat %>%
  left_join(fifa_dat, by = c("year", "month", "team_1" = "Team")) %>%
  rename(team_1_fifa = Pts) %>%
  left_join(fifa_dat, by = c("year", "month", "team_2" = "Team")) %>%
  rename(team_2_fifa = Pts) %>%
  left_join(odds_dat, by = c("date" = "match_date", "team_1" = "home_team", "team_2" = "away_team"))

head(dat)
glimpse(dat)
summary(dat)
```

It seems promising at first glance but there are missing FIFA rankings which shouldn't happen. 

```{r matched, message=FALSE, warning=FALSE, paged.print=TRUE}
matched <- dat %>%
  group_by(team_1) %>%
  summarise(match = sum(!is.na(team_1_fifa)),
            no_match = sum(is.na(team_1_fifa))) %>%
  mutate(perc = match/(match + no_match)) %>%
  arrange(perc)

matched %>%
  filter(perc == 0) %>%
  arrange(desc(no_match))

```

So - there are only 30 countries that don't match at all. Most of those are really small countries, or countries that have changed names. China is a weird one to be missing. Let's see what we can find in the FIFA data set.

```{r match-check, message=FALSE, warning=FALSE}
fifa_dat %>%
  filter(str_detect(Team, "China"))

betfair_dat %>%
  filter(str_detect(team_1, "China"))

fifa_dat %>%
  filter(str_detect(Team, "Ireland"))

betfair_dat %>%
  filter(str_detect(team_1, "Ireland"))
```

Hmm - so it didn't join because the FIFA data using "China PR". Also, it didn't match Northern Ireland or Republic of Ireland. I'm guessing that is the case for the rest of these 172 countries as well. I really should explore doing some fuzzy matching but it's only a small group and most of those teams aren't featuring in many matches so I'm just going to do it for the top 5. I manually worked out what these differences were. 

```{r fix-teams, message=FALSE, warning=FALSE}
fix_teams <- function(team){
    case_when(
      team == "China PR" ~ "China",
      team == "Republic of Ireland" ~ "Ireland",
      team == "CÃ´te d'Ivoire" ~ "Ivory Coast",
      team == "FYR Macedonia" ~ "Macedonia",
      team == "Bosnia and Herzegovina" ~ "Bosnia-Herzegovina",
      TRUE ~ team
    )
}

fifa_dat <- fifa_dat %>%
  mutate(Team = fix_teams(Team))

```

OK - that should at least pick the top 5. Those smaller teams I'll just have to not have any FIFA data. I suspect, given those level of teams aren't appearing in World Cups, that we won't have a big issue. The other missing data, since we matched the name properly at least once, are likely due to some kind of missing month/year combination, which I can deal with later. 

```{r join2, message=FALSE, warning=FALSE}
# Join data together
dat <- betfair_dat %>%
  left_join(fifa_dat, by = c("year", "month", "team_1" = "Team")) %>%
  rename(team_1_fifa = Pts) %>%
  left_join(fifa_dat, by = c("year", "month", "team_2" = "Team")) %>%
  rename(team_2_fifa = Pts) %>%
  left_join(odds_dat, by = c("date" = "match_date", "team_1" = "home_team", "team_2" = "away_team"))

head(dat)
glimpse(dat)
summary(dat)

```

# Submission
One of the important things is getting a good submission file in the right format. There is no point building a big model with heaps of variables and then not having those variables available for our actual submission! 

Luckily, Betfair has given us a starting point with the matches we need to predict. Let's load that file in (I'm hosting it [here](https://github.com/jimmyday12/plussixoneblog/blob/master/projects/world-cup-2018/john_smith_numbersman.csv) if you want it.)

```{r world_cup, message=FALSE, warning=FALSE}
world_cup <- read_csv(here::here("projects", "world-cup-2018", "john_smith_numbersman.csv"))
glimpse(world_cup)
```
First thing that jumps out is that the team's are in lower case. I'll need to fix that. Also, the date isn't being read properly. Lastly, those probability columns are just examples from Betfair so I can get rid of those.

```{r world_cup_clean, message=FALSE, warning=FALSE}
world_cup <- world_cup %>%
  mutate(date = dmy(date)) %>%
  mutate_at(vars(team_1, team_2), tools::toTitleCase) %>%
  select(date, match_id, team_1, team_2)
```

Now the other fields that we don't have are `tournament`, `is_team_1_home`, `is_team_2_home` and `is_neutral`. We can also hopefully get the `betfair` odds and the `fifa` points. 

```{r world_cup_add, message=FALSE, warning=FALSE}
# Add extra columns
world_cup <- world_cup %>%
  mutate(
    tournament = "World Cup 2018",
    is_team_1_home = ifelse(team_1 == "Russia", TRUE, FALSE),
    is_team_2_home = ifelse(team_2 == "Russia", TRUE, FALSE),
    is_neutral = !is_team_1_home & !is_team_2_home,
    year = year(date),
    month = month(date)
    )

# Join with fifa
fifa_dat_final <- fifa_dat %>% 
  group_by(Team) %>% 
  filter(row_number() == n()) %>%
  select(Team, Pts)

world_cup <- world_cup %>%
  left_join(fifa_dat_final, by = c("team_1" = "Team")) %>%
  rename(team_1_fifa = Pts) %>%
  left_join(fifa_dat_final, by = c("team_2" = "Team")) %>%
  rename(team_2_fifa = Pts)

```

I've also used the betfair API to get the betfair data. I haven't included the code for that as it uses login details, but you can see my script [here](https://github.com/jimmyday12/plussixoneblog/blob/master/projects/world-cup-2018/betfair_api.R) or just load the data from [here](https://github.com/jimmyday12/plussixoneblog/blob/master/projects/world-cup-2018/world_cup_2018_betfair.csv).

Let's load that in and join it to our existing world cup data frame. 

```{r world_cup_betfair, message=FALSE, warning=FALSE}
betfair_wc <- read_csv(here::here("projects", "world-cup-2018", "world_cup_2018_betfair.csv"))

world_cup <- world_cup %>%
  left_join(betfair_wc, by = c("date", "team_1", "team_2"))
glimpse(world_cup)
```

# Finishing up
Anyway, enough for now. Let's save it and we'll revisit in Part 3! 

```{r save, message=FALSE, warning=FALSE}
write_csv(dat, here::here("projects", "world-cup-2018", "combined-data.csv"))
write_csv(world_cup, here::here("projects", "world-cup-2018", "world-cup.csv"))
```


---
This is part of a series of posts on the World Cup Betfair datathon. See the links to others below.   
   
[Part 1 - Intro](https://plussixoneblog.com/post/football-world-cup-datathon-part-1)    
[Part 2 - Data Acquisition](https://plussixoneblog.com/post/football-world-cup-datathon-part-2)   
[Part 3 - Data Exploration and Feature Engineering]((https://plussixoneblog.com/post/football-world-cup-datathon-part-3)    
Part 4 - Models (coming soon)   
Part 5 - Review (coming soon)    

---
